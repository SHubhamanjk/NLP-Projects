{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a247f14c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import numpy as np\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "5d0ffb6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"Hello and welcome friends to NLP workshop.\n",
    "My name is shridhar mankar.\n",
    "I will be teaching you NLP from scratch.\n",
    "We will be learning about basic building block techniques in nlp,like tokenization, stemming, lemmatization, stopwords,pos tagging, bag of words and tf-idf.\n",
    "Now we are learning text summarization\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f0f1a5cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello and welcome friends to NLP workshop  My name is shridhar mankar  I will be teaching you NLP from scratch  We will be learning about basic building block techniques in nlp like tokenization  stemming  lemmatization  stopwords pos tagging  bag of words and tf idf  Now we are learning text summarization'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pure_text = re.sub('[^a-zA-Z]', ' ', text )\n",
    "pure_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "0adedfdd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hello and welcome friends to NLP workshop.',\n",
       " 'My name is shridhar mankar.',\n",
       " 'I will be teaching you NLP from scratch.',\n",
       " 'We will be learning about basic building block techniques in nlp,like tokenization, stemming, lemmatization, stopwords,pos tagging, bag of words and tf-idf.',\n",
       " 'Now we are learning text summarization']"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences = nltk.sent_tokenize(text)\n",
    "sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "f5862bfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = nltk.corpus.stopwords.words('english')\n",
    "word_freq = {}\n",
    "for word in nltk.word_tokenize(pure_text):\n",
    "    if word not in stopwords:\n",
    "        if word not in word_freq.keys():\n",
    "            word_freq[word] = 1\n",
    "        else:\n",
    "            word_freq[word] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "542a55b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Hello': 1,\n",
       " 'welcome': 1,\n",
       " 'friends': 1,\n",
       " 'NLP': 2,\n",
       " 'workshop': 1,\n",
       " 'My': 1,\n",
       " 'name': 1,\n",
       " 'shridhar': 1,\n",
       " 'mankar': 1,\n",
       " 'I': 1,\n",
       " 'teaching': 1,\n",
       " 'scratch': 1,\n",
       " 'We': 1,\n",
       " 'learning': 2,\n",
       " 'basic': 1,\n",
       " 'building': 1,\n",
       " 'block': 1,\n",
       " 'techniques': 1,\n",
       " 'nlp': 1,\n",
       " 'like': 1,\n",
       " 'tokenization': 1,\n",
       " 'stemming': 1,\n",
       " 'lemmatization': 1,\n",
       " 'stopwords': 1,\n",
       " 'pos': 1,\n",
       " 'tagging': 1,\n",
       " 'bag': 1,\n",
       " 'words': 1,\n",
       " 'tf': 1,\n",
       " 'idf': 1,\n",
       " 'Now': 1,\n",
       " 'text': 1,\n",
       " 'summarization': 1}"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "dafe3b34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['Hello', 'welcome', 'friends', 'NLP', 'workshop', 'My', 'name', 'shridhar', 'mankar', 'I', 'teaching', 'scratch', 'We', 'learning', 'basic', 'building', 'block', 'techniques', 'nlp', 'like', 'tokenization', 'stemming', 'lemmatization', 'stopwords', 'pos', 'tagging', 'bag', 'words', 'tf', 'idf', 'Now', 'text', 'summarization'])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_freq.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "d727c38f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_values([1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_freq.values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "caacbfa8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_freq = max(word_freq.values())\n",
    "max_freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "62bc2186",
   "metadata": {},
   "outputs": [],
   "source": [
    "for word in word_freq.keys():\n",
    "    word_freq[word] = (word_freq[word]/max_freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "c9e93cac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Hello': 0.5,\n",
       " 'welcome': 0.5,\n",
       " 'friends': 0.5,\n",
       " 'NLP': 1.0,\n",
       " 'workshop': 0.5,\n",
       " 'My': 0.5,\n",
       " 'name': 0.5,\n",
       " 'shridhar': 0.5,\n",
       " 'mankar': 0.5,\n",
       " 'I': 0.5,\n",
       " 'teaching': 0.5,\n",
       " 'scratch': 0.5,\n",
       " 'We': 0.5,\n",
       " 'learning': 1.0,\n",
       " 'basic': 0.5,\n",
       " 'building': 0.5,\n",
       " 'block': 0.5,\n",
       " 'techniques': 0.5,\n",
       " 'nlp': 0.5,\n",
       " 'like': 0.5,\n",
       " 'tokenization': 0.5,\n",
       " 'stemming': 0.5,\n",
       " 'lemmatization': 0.5,\n",
       " 'stopwords': 0.5,\n",
       " 'pos': 0.5,\n",
       " 'tagging': 0.5,\n",
       " 'bag': 0.5,\n",
       " 'words': 0.5,\n",
       " 'tf': 0.5,\n",
       " 'idf': 0.5,\n",
       " 'Now': 0.5,\n",
       " 'text': 0.5,\n",
       " 'summarization': 0.5}"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "1f843ceb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentence--> Hello and welcome friends to NLP workshop.\n",
      "word--> Hello\n",
      "word--> and\n",
      "word--> welcome\n",
      "word--> friends\n",
      "word--> to\n",
      "word--> NLP\n",
      "word--> workshop\n",
      "word--> .\n",
      "sentence--> My name is shridhar mankar.\n",
      "word--> My\n",
      "word--> name\n",
      "word--> is\n",
      "word--> shridhar\n",
      "word--> mankar\n",
      "word--> .\n",
      "sentence--> I will be teaching you NLP from scratch.\n",
      "word--> I\n",
      "word--> will\n",
      "word--> be\n",
      "word--> teaching\n",
      "word--> you\n",
      "word--> NLP\n",
      "word--> from\n",
      "word--> scratch\n",
      "word--> .\n",
      "sentence--> We will be learning about basic building block techniques in nlp,like tokenization, stemming, lemmatization, stopwords,pos tagging, bag of words and tf-idf.\n",
      "word--> We\n",
      "word--> will\n",
      "word--> be\n",
      "word--> learning\n",
      "word--> about\n",
      "word--> basic\n",
      "word--> building\n",
      "word--> block\n",
      "word--> techniques\n",
      "word--> in\n",
      "word--> nlp\n",
      "word--> ,\n",
      "word--> like\n",
      "word--> tokenization\n",
      "word--> ,\n",
      "word--> stemming\n",
      "word--> ,\n",
      "word--> lemmatization\n",
      "word--> ,\n",
      "word--> stopwords\n",
      "word--> ,\n",
      "word--> pos\n",
      "word--> tagging\n",
      "word--> ,\n",
      "word--> bag\n",
      "word--> of\n",
      "word--> words\n",
      "word--> and\n",
      "word--> tf-idf\n",
      "word--> .\n",
      "sentence--> Now we are learning text summarization\n",
      "word--> Now\n",
      "word--> we\n",
      "word--> are\n",
      "word--> learning\n",
      "word--> text\n",
      "word--> summarization\n"
     ]
    }
   ],
   "source": [
    "sentence_values = {}\n",
    "for s in sentences:\n",
    "    print('sentence-->',s)\n",
    "    for word in nltk.word_tokenize(s):\n",
    "        print('word-->',word)\n",
    "        if word in word_freq.keys():\n",
    "            if s not in sentence_values.keys():\n",
    "                sentence_values[s] = word_freq[word]\n",
    "            else:\n",
    "                sentence_values[s] += word_freq[word]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "6bb23182",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Hello and welcome friends to NLP workshop.': 3.0,\n",
       " 'My name is shridhar mankar.': 2.0,\n",
       " 'I will be teaching you NLP from scratch.': 2.5,\n",
       " 'We will be learning about basic building block techniques in nlp,like tokenization, stemming, lemmatization, stopwords,pos tagging, bag of words and tf-idf.': 8.5,\n",
       " 'Now we are learning text summarization': 2.5}"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "894c7c84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We will be learning about basic building block techniques in nlp,like tokenization, stemming, lemmatization, stopwords,pos tagging, bag of words and tf-idf. Hello and welcome friends to NLP workshop. I will be teaching you NLP from scratch.\n"
     ]
    }
   ],
   "source": [
    "import heapq\n",
    "summary = heapq.nlargest(3, sentence_values, key=sentence_values.get)\n",
    "summary = ' '.join(summary)\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50461bb5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
